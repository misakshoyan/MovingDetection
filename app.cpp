#include "app.h"

// ObjectTrackingCPP.cpp

#include<opencv2/core/core.hpp>
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
#include <opencv2/bgsegm.hpp> //for MOG, GMG
#include <opencv2/tracking.hpp>
#include <opencv2/core/ocl.hpp>

#include<iostream>
#include <algorithm>


#define SHOW_STEPS            // un-comment or comment this line to show steps or not

// global variables ///////////////////////////////////////////////////////////////////////////////
const cv::Scalar SCALAR_BLACK = cv::Scalar(0.0, 0.0, 0.0);
const cv::Scalar SCALAR_WHITE = cv::Scalar(255.0, 255.0, 255.0);
const cv::Scalar SCALAR_YELLOW = cv::Scalar(0.0, 255.0, 255.0);
const cv::Scalar SCALAR_GREEN = cv::Scalar(0.0, 200.0, 0.0);
const cv::Scalar SCALAR_RED = cv::Scalar(0.0, 0.0, 255.0);




App* App::s_instance = NULL;

// Singleton
App* App::createApp()
{
    if (s_instance == NULL) {
        s_instance = new App();
    }

    return s_instance;
}

App::App()
{
    m_settings = Settings::createSettings();
}

void App::setVideoFileName(QString fileName)
{
    m_videoFileName = fileName;
}

///////////////////////////////////////////////////////////////////////////////////////////////////
void App::StartApp()
{
    cv::VideoCapture capVideo;

    cv::Mat imgFrame1;
    cv::Mat imgFrame2;

    std::vector<Blob> blobs;

    capVideo.open(m_videoFileName.toStdString());

    if (!capVideo.isOpened()) {                                                 // if unable to open video file
        std::cout << "error reading video file" << std::endl << std::endl;      // show error message
        return;
    }

    if (capVideo.get(CV_CAP_PROP_FRAME_COUNT) < 2) {
        std::cout << "error: video file must have at least two frames";
        return;
    }

    capVideo.read(imgFrame1);

    capVideo.read(imgFrame2);

    char chCheckForEscKey = 0;

    bool blnFirstFrame = true;
    bool videoEnded = false;

    int frameCount = 2;

    //global variables
    cv::Mat frame; //current frame
    cv::Mat fgMaskKNN; //fg mask fg mask generated by KNN method

    cv::Ptr< cv::BackgroundSubtractor> pKNN; //KNN Background subtractor

    pKNN = cv::createBackgroundSubtractorKNN(m_settings->m_historyLength, 400, m_settings->m_detectShadows);
    pKNN->apply(imgFrame1, fgMaskKNN);

    while (capVideo.isOpened() && chCheckForEscKey != 27) {

        std::vector<Blob> currentFrameBlobs;

        cv::Mat imgFrame2Copy = imgFrame2.clone();

        cv::Mat imgThresh;

        pKNN->apply(imgFrame2, fgMaskKNN);
        fgMaskKNN.convertTo(fgMaskKNN, CV_8U);
        cv::Mat maskToShow1;
        cv::resize(fgMaskKNN, maskToShow1, cv::Size(fgMaskKNN.size().width/2, fgMaskKNN.size().height/2));
        imshow("before smooth", maskToShow1);

        if (m_settings->m_isMedianBlur) {
            cv::blur(fgMaskKNN, fgMaskKNN, cv::Size(15, 15));
        } else if (m_settings->m_isGaussianBlur) {
            cv::GaussianBlur(fgMaskKNN, fgMaskKNN, cv::Size(15,15),0);
        }
        threshold(fgMaskKNN, imgThresh, 150, 255, cv::THRESH_BINARY);

        cv::Mat maskToShow2;
        cv::resize(fgMaskKNN, maskToShow2, cv::Size(fgMaskKNN.size().width/2, fgMaskKNN.size().height/2));
        imshow("after smooth", maskToShow2);

        cv::Mat imgThreshCopy = imgThresh.clone();

        std::vector<std::vector<cv::Point> > contours;

        cv::findContours(imgThreshCopy, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);

        drawAndShowContours(imgThresh.size(), contours, "imgContours");

        std::vector<std::vector<cv::Point> > convexHulls(contours.size());

        for (unsigned int i = 0; i < contours.size(); i++) {
            cv::convexHull(contours[i], convexHulls[i]);
        }

        drawAndShowContours(imgThresh.size(), convexHulls, "imgConvexHulls");

        for (auto &convexHull : convexHulls) {
            Blob possibleBlob(convexHull);

            if (possibleBlob.currentBoundingRect.area() >= m_settings->m_minBoundingRectArea &&
                possibleBlob.dblCurrentAspectRatio >= m_settings->m_minBoundingRectAspectRatio &&
                possibleBlob.dblCurrentAspectRatio <= m_settings->m_maxBoundingRectAspectRatio &&
                possibleBlob.currentBoundingRect.width >= m_settings->m_minBoundingRectWidth &&
                possibleBlob.currentBoundingRect.height >= m_settings->m_minBoundingRectHeight &&
                possibleBlob.dblCurrentDiagonalSize >= m_settings->m_minBoundingRectDiagonalSize &&
                (cv::contourArea(possibleBlob.currentContour) / (double)possibleBlob.currentBoundingRect.area()) >= m_settings->m_minContourSizeDivBoundingRect) {
                currentFrameBlobs.push_back(possibleBlob);
            }

        }

        drawAndShowContours(imgThresh.size(), currentFrameBlobs, "imgCurrentFrameBlobs");

        if (blnFirstFrame == true) {
            for (auto &currentFrameBlob : currentFrameBlobs) {
                blobs.push_back(currentFrameBlob);
            }
        }
        else {
            matchCurrentFrameBlobsToExistingBlobs(blobs, currentFrameBlobs);
        }

        drawAndShowContours(imgThresh.size(), blobs, "imgBlobs");

        // get another copy of frame 2 since we changed the previous frame 2 copy in the processing above
        imgFrame2Copy = imgFrame2.clone();

        for (auto &existingBlob : blobs) {
            if (existingBlob.blnStillBeingTracked && existingBlob.centerPositions.size() >= 2) {
                drawDirectionLine(imgFrame2Copy, getDirectionLineStartEndPoints(existingBlob));
            }
        }

        drawBlobInfoOnImage(blobs, imgFrame2Copy);

        cv::Mat imgFrame2Copy1;
        //cv::resize(imgFrame2Copy, imgFrame2Copy1, cv::Size(imgFrame2Copy.size().width/2, imgFrame2Copy.size().height/2));
        cv::imshow("Result", imgFrame2Copy);

        currentFrameBlobs.clear();

        imgFrame1 = imgFrame2.clone();           // move frame 1 up to where frame 2 is

        if ((capVideo.get(CV_CAP_PROP_POS_FRAMES) + 1) < capVideo.get(CV_CAP_PROP_FRAME_COUNT)) {
            capVideo.read(imgFrame2);
        }
        else {
            std::cout << "end of video\n";
            videoEnded = true;
            break;
        }

        blnFirstFrame = false;
        frameCount++;

        chCheckForEscKey = cv::waitKey(((m_settings->m_speedLevel - 1) * 100) + 1);

        if (chCheckForEscKey == 112) { // p key pressed
            bool enterKeyPressed = false;
            while (!enterKeyPressed) {
                chCheckForEscKey = cv::waitKey(0);
                if (chCheckForEscKey == 10) { // Enter key pressed
                    enterKeyPressed = true;
                }
            }

        }
    }

    if (chCheckForEscKey == 27 || videoEnded) {
        cv::destroyAllWindows();
    }
}

struct NeedToDelete : public std::unary_function<Blob&, bool>
{
    bool operator()(Blob& blob) const
    {
        if (blob.intNumOfConsecutiveFramesWithoutAMatch >= 5) {
            return true;
        }

        return false;
    }
};

///////////////////////////////////////////////////////////////////////////////////////////////////
void App::matchCurrentFrameBlobsToExistingBlobs(std::vector<Blob> &existingBlobs, std::vector<Blob> &currentFrameBlobs) {

    for (auto &existingBlob : existingBlobs) {

        existingBlob.blnCurrentMatchFoundOrNewBlob = false;

        existingBlob.predictNextPosition();
    }

    for (auto &currentFrameBlob : currentFrameBlobs) {

        int intIndexOfLeastDistance = 0;
        double dblLeastDistance = 100000.0;

        for (unsigned int i = 0; i < existingBlobs.size(); i++) {
            if (existingBlobs[i].blnStillBeingTracked == true) {
                double dblDistance = distanceBetweenPoints(currentFrameBlob.centerPositions.back(),
                                                           existingBlobs[i].predictedNextPosition);

                if (dblDistance < dblLeastDistance) {
                    dblLeastDistance = dblDistance;
                    intIndexOfLeastDistance = i;
                }
            }
        }

        if (dblLeastDistance < currentFrameBlob.dblCurrentDiagonalSize * m_settings->m_maxDistanceCoefficient) {
            addBlobToExistingBlobs(currentFrameBlob, existingBlobs, intIndexOfLeastDistance);
        }
        else {
            addNewBlob(currentFrameBlob, existingBlobs);
        }

    }

    for (auto &existingBlob : existingBlobs) {

        if (existingBlob.blnCurrentMatchFoundOrNewBlob == false) {
            existingBlob.intNumOfConsecutiveFramesWithoutAMatch++;
        }

        if (existingBlob.intNumOfConsecutiveFramesWithoutAMatch >= 2) {
            existingBlob.blnStillBeingTracked = false;
        }

    }

    existingBlobs.erase( std::remove_if( existingBlobs.begin(), existingBlobs.end(), NeedToDelete() ), existingBlobs.end() );
}

std::pair<cv::Point, cv::Point> App::getDirectionLineStartEndPoints(Blob &blob)
{
    // y = kx + b
    int numPositions = blob.centerPositions.size();
    cv::Point pos1 = blob.centerPositions[numPositions - 2];
    cv::Point pos2  = blob.centerPositions.back();
    int deltaY = pos2.y - pos1.y;
    int deltaX = pos2.x - pos1.x;

    double r = (blob.currentBoundingRect.width <= blob.currentBoundingRect.height) ? blob.currentBoundingRect.width / 2
                                                                                : blob.currentBoundingRect.height / 2;

    if (deltaX == 0 && deltaY == 0) {
        return std::make_pair(pos2, pos2);
    }

    if (deltaX == 0) {
        if (deltaY > 0) {
            return std::make_pair(pos2, cv::Point(pos2.x, pos2.y + r));
        } else {
            return std::make_pair(pos2, cv::Point(pos2.x, (pos2.y - r < 0) ? 0 : (pos2.y - r)));
        }
    }

    if (deltaY == 0) {
        if (deltaX > 0) {
            return std::make_pair(pos2, cv::Point(pos2.x + r, pos2.y));
        } else {
            return std::make_pair(pos2, cv::Point(((pos2.x - r < 0) ? 0 : (pos2.x - r)), pos2.y));
        }
    }

    double k = (double)deltaY / deltaX;
    double b = pos1.y - pos1.x * k;

    cv::Point endPoint;
    int d = std::sqrt(std::pow(deltaY, 2) + std::pow(deltaX, 2));
    if (pos2.y < pos1.y) {
        int h = pos1.y - pos2.y;
        double h1 = h * r / d;
        endPoint.y = (pos2.y - h1 < 0) ? 0
                                       : pos2.y - h1;
        endPoint.x = ((endPoint.y - b) / k < 0) ? 0
                                                : (endPoint.y - b) / k;
    } else {
        int h = pos2.y - pos1.y;
        double h1 = h * r / d;
        endPoint.y = pos2.y + h1;
        endPoint.x = ((endPoint.y - b) / k < 0) ? 0
                                                : (endPoint.y - b) / k;
    }

    if (std::abs(pos2.y - endPoint.y) > 200 )
    {
        std::cout << std::endl;
    }
    return std::make_pair(pos2, endPoint);
}

void App::drawDirectionLine(cv::Mat &img, std::pair<cv::Point, cv::Point> startEndPositions)
{
    if (m_settings->m_drawDirectionLine) {
        cv::arrowedLine(img, startEndPositions.first, startEndPositions.second, cv::Scalar( 255, 255, 255 ), 2, 8, 0, 0.5);
    }
}


///////////////////////////////////////////////////////////////////////////////////////////////////
void App::addBlobToExistingBlobs(Blob &currentFrameBlob, std::vector<Blob> &existingBlobs, int &intIndex) {

    existingBlobs[intIndex].currentContour = currentFrameBlob.currentContour;
    existingBlobs[intIndex].currentBoundingRect = currentFrameBlob.currentBoundingRect;

    existingBlobs[intIndex].centerPositions.push_back(currentFrameBlob.centerPositions.back());

    existingBlobs[intIndex].dblCurrentDiagonalSize = currentFrameBlob.dblCurrentDiagonalSize;
    existingBlobs[intIndex].dblCurrentAspectRatio = currentFrameBlob.dblCurrentAspectRatio;

    existingBlobs[intIndex].blnStillBeingTracked = true;
    existingBlobs[intIndex].blnCurrentMatchFoundOrNewBlob = true;
    existingBlobs[intIndex].intNumOfConsecutiveFramesWithoutAMatch = 0;
}

///////////////////////////////////////////////////////////////////////////////////////////////////
void App::addNewBlob(Blob &currentFrameBlob, std::vector<Blob> &existingBlobs) {

    currentFrameBlob.blnCurrentMatchFoundOrNewBlob = true;

    existingBlobs.push_back(currentFrameBlob);
}

///////////////////////////////////////////////////////////////////////////////////////////////////
double App::distanceBetweenPoints(cv::Point point1, cv::Point point2) {

    int intX = abs(point1.x - point2.x);
    int intY = abs(point1.y - point2.y);

    return(sqrt(pow(intX, 2) + pow(intY, 2)));
}

///////////////////////////////////////////////////////////////////////////////////////////////////
void App::drawAndShowContours(cv::Size imageSize, std::vector<std::vector<cv::Point> > contours, std::string strImageName) {
    cv::Mat image(imageSize, CV_8UC3, SCALAR_BLACK);

    cv::drawContours(image, contours, -1, SCALAR_WHITE, -1);

    cv::Mat imToShow;
    cv::resize(image, imToShow, cv::Size(image.size().width/2, image.size().height/2));
    cv::imshow(strImageName, imToShow);
}

///////////////////////////////////////////////////////////////////////////////////////////////////
void App::drawAndShowContours(cv::Size imageSize, std::vector<Blob> blobs, std::string strImageName) {

    cv::Mat image(imageSize, CV_8UC3, SCALAR_BLACK);

    std::vector<std::vector<cv::Point> > contours;

    for (auto &blob : blobs) {
        if (blob.blnStillBeingTracked == true) {
            contours.push_back(blob.currentContour);
        }
    }

    cv::drawContours(image, contours, -1, SCALAR_WHITE, -1);

    cv::Mat imToShow;
    cv::resize(image, imToShow, cv::Size(image.size().width/2, image.size().height/2));
    cv::imshow(strImageName, imToShow);
}

///////////////////////////////////////////////////////////////////////////////////////////////////
void App::drawBlobInfoOnImage(std::vector<Blob> &blobs, cv::Mat &imgFrame2Copy) {

    for (unsigned int i = 0; i < blobs.size(); i++) {

        if (blobs[i].blnStillBeingTracked == true) {
            cv::rectangle(imgFrame2Copy, blobs[i].currentBoundingRect, SCALAR_RED, 1);

            if (m_settings->m_showObjectNumber) {
                int intFontFace = CV_FONT_HERSHEY_SIMPLEX;
                double dblFontScale = blobs[i].dblCurrentDiagonalSize / 60.0;
                int intFontThickness = (int)std::round(dblFontScale * 1.0);

                cv::putText(imgFrame2Copy, std::to_string(i), blobs[i].centerPositions.back(),
                            intFontFace, dblFontScale, SCALAR_GREEN, intFontThickness);
            }
        }
    }
}




